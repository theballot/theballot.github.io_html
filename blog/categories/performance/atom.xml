<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: performance | Artsy Engineering]]></title>
  <link href="http://artsy.github.io/blog/categories/performance/atom.xml" rel="self"/>
  <link href="http://artsy.github.io/"/>
  <updated>2018-12-16T10:16:31+00:00</updated>
  <id>http://artsy.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Measuring Performance in Grape APIs with NewRelic RPM]]></title>
    <link href="http://artsy.github.io/blog/2012/11/29/measuring-performance-in-grape-apis-with-new-relic/"/>
    <updated>2012-11-29T21:21:00+00:00</updated>
    <id>http://artsy.github.io/blog/2012/11/29/measuring-performance-in-grape-apis-with-new-relic</id>
    <content type="html"><![CDATA[<p>Knowing how well your API performs in real time is essential to any successful project. That's because you can't fix what you can't measure.</p>

<p>We use and heavily contribute to <a href="http://github.com/intridea/grape">Grape</a>, a Ruby API DSL. Grape is a Rack middleware and we have been reporting API performance data to <a href="http://newrelic.com/">NewRelic</a> with code from <a href="http://code.dblock.org/new-relic-performance-instrumentation-with-grape-api">my older blog post</a>.</p>

<p>It's time to improve the reporting implementation and address performance monitoring in both development and production environments. Here's what a single API request breakdown is going to look like.</p>

<p><img src="/images/2012-11-29-measuring-performance-in-grape-apis-with-new-relic/transaction-detail.png"></p>

<!-- more -->


<a name="NewRelic.RPM"></a>
<h2>NewRelic RPM</h2>

<p>The first step is to add the <code>newrelic_rpm</code> gem to Gemfile, which implements the actual realtime performance reporting to NewRelic. We also use <a href="https://github.com/mongoid/mongoid">Mongoid</a> and the <a href="https://github.com/mongoid/moped">Moped</a> MongoDB Ruby driver, which can be instrumented with <code>newrelic_moped</code>.</p>

<pre><code class="ruby Gemfile">gem "newrelic_moped", "0.0.3"
gem "newrelic_rpm", "3.3.3"
</code></pre>

<p>You will need <code>config/newrelic.yml</code> in your application. Ours can be found in <a href="https://gist.github.com/4170458">this gist</a> and works well both locally and on Heroku.</p>

<a name="Instrumenting.Grape"></a>
<h2>Instrumenting Grape</h2>

<p>In the past we used <a href="https://gist.github.com/1233422">NewRelic::Agent::Instrumentation::API</a>, which works for any generic Rack middleware. This would report all API calls to NewRelic, but would treat requests to <em>/api/artist/andy-warhol</em> and <em>/api/artist/wassily-kandinsky</em> as unrelated. That is because the instrumenter is a Rack middleware that wraps Grape requests <em>before</em> they reach Grape. The only information available is the request URL, and not the actual API route that is going to be matched when the request is processed.</p>

<p>We want both requests to <em>/api/artist/andy-warhol</em> and <em>/api/artist/wassily-kandinsky</em> to be treated as <em>/api/artist/:id</em>. Lets insert a middleware inside Grape itself, once the URL has been matched to a route.</p>

<pre><code class="ruby api.rb">class API &lt;&lt; Grape::API
  use ApiNewRelicInstrumenter
  ...
end
</code></pre>

<p>The new instrumenter has access to the current API endpoint via <code>env['api.endpoint']</code> and reports data via NewRelic's <code>ControllerInstrumentation</code>.</p>

<pre><code class="ruby">class ApiNewRelicInstrumenter &lt; Grape::Middleware::Base
  include NewRelic::Agent::Instrumentation::ControllerInstrumentation

  def call(env)
    trace_options = {
      category: :rack,
      path: env['api.endpoint'].routes.first.route_path,
      request: request,
      ...
    }

    perform_action_with_newrelic_trace(trace_options) do
      yield
    end

  end
end
</code></pre>

<p>The complete code for <code>ApiNewRelicInstrumenter</code> can be found in <a href="https://gist.github.com/4170469">this gist</a>. It supports enabling and disabling performance reporting by setting <code>NEW_RELIC_ID</code> and works around NewRelic's method name limitations (these cannot contain slashes).</p>

<a name="Development.Environment"></a>
<h2>Development Environment</h2>

<p>You can now see NewRelic performance data in development mode, too. If you mount Grape inside Rails run <code>NEW_RELIC_ID=foo rails s</code>. Navigate to <em>http://localhost:3000/newrelic</em> to see your local traces.</p>

<p><img src="/images/2012-11-29-measuring-performance-in-grape-apis-with-new-relic/developer-mode.png"></p>

<p>Drill into an individual request to find several detailed breakdowns of how time was spent, including specific MongoDB queries (under "SQL", naturally).</p>

<p><img src="/images/2012-11-29-measuring-performance-in-grape-apis-with-new-relic/sql-detail.png"></p>

<p>NewRelic is a commercial product, but you can run development mode for free! Note that enabling this will triple your local Rails boot time: we enable development mode by setting <code>development_mode: &lt;%= !!ENV['NEW_RELIC_ID'] %&gt;</code> in <a href="https://gist.github.com/4170458">newrelic.rpm</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RESTful API Caching with Garner]]></title>
    <link href="http://artsy.github.io/blog/2012/05/30/restful-api-caching-with-garner/"/>
    <updated>2012-05-30T21:21:00+00:00</updated>
    <id>http://artsy.github.io/blog/2012/05/30/restful-api-caching-with-garner</id>
    <content type="html"><![CDATA[<p>Implementing server-side RESTful API caching is hard. In a straightforward API all the expiry decisions can be made automatically based on the URL, but most real world APIs that add requirements around object relationships or user authorization make caching particularly challenging.</p>

<p>At <a href="http://goruco.com/">GoRuCo</a> we open-sourced <a href="http://github.com/artsy/garner">Garner</a>, a cache implementation of the concepts described in this post. To "garner" means to gather data from various sources and to make it readily available in one place, kind-of like a cache! Garner works today with the <a href="http://github.com/intridea/grape">Grape API framework</a> and the <a href="http://github.com/mongoid/mongoid">Mongoid ODM</a>. We encourage you to fork the project, extend our library to other systems and contribute your code back, if you find it useful.</p>

<p>Garner implements the Artsy API caching cookbook that has been tried by fire in production.</p>

<!-- more -->


<a name="Enabling.Caching.of.Static.Data"></a>
<h3>Enabling Caching of Static Data</h3>

<p>Caching static data is fairly easy: set <code>Cache-Control</code> and <code>Expires</code> headers in the HTTP response.</p>

<pre><code class="ruby">expire_in = 60 * 60 * 24 * 365
header "Cache-Control", "private, max-age=#{expire_in}"
header "Expires", CGI.rfc1123_date(Time.now.utc + expire_in)
</code></pre>

<p>This example indicates to a cache in front of your service (CDN, proxy or user's browser) that the data expires in a year and that it's private for this user. When caching truly static data, such as images, use <code>public</code>. Your CDN or proxy, such as <a href="https://www.varnish-cache.org/">Varnish</a> that sits in front of Artsy on <a href="http://www.heroku.com/">Heroku</a>, will cache the data and subsequent requests won't even need to hit your server, even though it could potentially serve different content every time.</p>

<a name="Disabling.Caching.of.Dynamic.Data"></a>
<h3>Disabling Caching of Dynamic Data</h3>

<p>Caching dynamic data is slightly more involved. Let's begin with a simple Ruby API that returns a counter.</p>

<pre><code class="ruby">class API &lt; Grape::API
  def count
    { count : 0 }
  end
end
</code></pre>

<p>This kind of dynamic data cannot have a well-defined expiration time. The counter may be incremented at any time via another API call or process, so we must tell the client not to cache it. This is accomplished by setting the value of <code>Cache-Control</code> to <code>private, max-age=0, must-revalidate</code>. The <code>private</code> option instructs the client that it's allowed to store data in a private cache (unnecessary, but is known to work around overzealous cache implementations), <code>max-age</code> that it must check with the server every time it needs this data and <code>must-revalidate</code> prevents gateways from returning a response if your API server is unreachable. An additional <code>Expires</code> header set to a past date (usually January 1st 1990), will make double-sure the entire request expires immediately with old browsers.</p>

<p>Garner provides <a href="https://github.com/dblock/garner/blob/master/lib/garner/middleware/cache/bust.rb">Garner::Middleware::Cache::Bust</a> a Rack middleware that accomplishes just that.</p>

<a name="If-Modified-Since..ETags.and.If-None-Match"></a>
<h3>If-Modified-Since, ETags and If-None-Match</h3>

<p>Given our API example, a client may want to retrieve the value of the counter and, for example, run a job every time the value changes. As it stands, the current API requires an effort on the client's part to remember the previous value and compare it every time it makes an API call. This can be avoided by asking the server for a new counter if the value has changed since last time it was retrieved.</p>

<p>One option for the client is to include an <code>If-Modified-Since</code> header with a timestamp. The server could then choose to respond with <code>304 Not Modified</code> if the counter hasn't changed since the timestamp in <code>If-Modified-Since</code>. While this may be acceptable for certain data, timestamps have a granularity of seconds. A counter may be modified multiple times during the same second, therefore preventing it from retrieving the result of the second modification.</p>

<p>A more robust solution is to generate a unique signature, called ETag, for this data and to use it to find out whether the counter has changed. There exists a generic <a href="https://github.com/rack/rack/blob/master/lib/rack/etag.rb">Rack::ETag</a> middleware that sets ETags on all text bodies. Adding the middleware would produce an ETag for every response from the API. You can now combine <code>Rack::ETag</code> and <code>Rack::Cache</code> - a client makes a request with an <code>If-None-Match: Etag</code> header and the server returns a <code>304 Not Modified</code> if the data hasn't changed, without sending the data.</p>

<a name="Memcached.via.Dalli.and.Rails.Cache"></a>
<h3>Memcached via Dalli and Rails.Cache</h3>

<p>There's an obvious problem with <code>Rack::Cache</code>. In order for it to serve a <code>304 Not Modified</code> response it must compare the ETag from the request with the ETag generated from the body of the current response. So it saves bandwidth, but doesn't save execution time on the server. We'd also like the server to cache the entire response and therefore avoid any heavy processing, such as querying a database.</p>

<p>A typical Ruby cache supports a block syntax. The following example returns a cached copy when available or executes the supplied block and stores the result in the cache. In this context <code>cache</code> could be <code>Rails.cache</code> or an instance of <code>ActiveSupport::Cache::FileStore</code>. We use <code>Rails.cache</code> with <a href="http://memcached.org/">Memcached</a> via the <a href="https://github.com/mperham/dalli">dalli gem</a> in production.</p>

<pre><code class="ruby">cache("count") do
  { count : 0 }
end
</code></pre>

<p>The parameter of the <code>cache</code> call is the cache key that uniquely identifies the cache entry. Hard-coding cache keys is tedious, so we can generate a key from the API version, route and request parameters.</p>

<pre><code class="ruby">def cache_key
  options = { }
  options[:version] = version
  options[:path] = request.path
  options[:params] = request.GET
  Digest::MD5.hexdigest(options.to_json)
end
</code></pre>

<p>This generic approach to key generation is fine to get one started, but is largely insufficient for real-world applications.</p>

<a name="Production-Grade.Cache.Keys.and.Model.Binding"></a>
<h3>Production-Grade Cache Keys and Model Binding</h3>

<p>Most large scale web properties operate on data with the following requirements.</p>

<ul>
<li>Partition cache in sync with object ownership and permissions. For example, a <code>Widget</code> may have different representations depending on whether <code>current_user</code> owns it or not or may choose to return a <code>401 Access Denied</code> in some of the cases.</li>
<li>Retrieve objects from cache no matter where the calling code appears. The above strategy would generate identical keys from two different locations within the same function.</li>
<li>Invalidate entire cached collections when one of the objects in a collection has changed. For example, invalidate all cached instances of <code>Widget</code> when a new <code>WidgetCategory</code> is created and forces a reorganization of those widgets.</li>
</ul>


<p>Garner will help you introduce such aspects of your domain model into the cache and solve all these.</p>

<p>A cache is a collection of flat name/value pairs. We'll specify object relationships within each key by chaining model names, field values and by using wildcards where appropriate. For example, <code>User/id=12,Widget/id=45,Gadget/*</code> binds the cache value to changes in <code>User</code> with id=12, <code>Widget</code> with id=45 and any instance of <code>Gadget</code>.</p>

<pre><code class="ruby">cache(bind: [[User, { id: current_user.id }], [Widget, { id: params[:widget_id] }], [Gadget] ])
  Widget.where({ id: params[:widget_id], user_id: current_user.id }).first.as_json
end
</code></pre>

<p>Binding to multiple objects or classes can also be reasoned about as a way to partition the cache. Adding structure into the fields lets us reason about the relationships between various instances of data in the cache.</p>

<a name="Role-Based.Caching"></a>
<h3>Role-Based Caching</h3>

<p>Role-Based caching is a subset of the generic problem of binding data to groups of other objects. For example, a <code>Widget</code> may have a different representation for an <code>admin</code> vs. a <code>user</code>. In Garner you can inject something called a "key strategy" into the current key generation pipeline. A strategy is a plain module that must implement two methods: <code>field</code> and <code>apply</code>. The former should define a unique key name and the latter applies the strategy within a context.</p>

<p>The following example introduces the role of the current user into the cache key.</p>

<pre><code class="ruby">module MyApp
  module Garner
    module RoleStrategy
      class &lt;&lt; self
        def field
          :role
        end
        def apply(key, context = {})
          key.merge { :role =&gt; current_user.role }
        end
      end
    end
  end
end
</code></pre>

<p>Garner key strategies can be currently set at application startup time.</p>

<pre><code class="ruby">Garner::Cache::ObjectIdentity::KEY_STRATEGIES = [
  Garner::Strategies::Keys::Caller, # support multiple calls from the same function
  MyApp::Garner::RoleStrategy, # custom strategy for role-based access
  Garner::Strategies::Keys::RequestPath # injects the HTTP request's URL
]
</code></pre>

<a name="Multiple.Calls.from.the.Same.Function"></a>
<h3>Multiple Calls from the Same Function</h3>

<p>Binding to the same set of objects within the same function call will produce the same key. To solve this in a generic way we can examine the call stack, find the caller that's not within the helper module and inject it in the key options.</p>

<pre><code class="ruby">api_caller = caller.detect { |line| !(line =~ /\/#{File.basename(__FILE__)}/) }
api_caller_line = api_caller.match(/(.*\.rb:[0-9]*):/) if api_caller
options[:caller] = api_caller_line[1] if api_caller_line
</code></pre>

<p>Garner implements this as <a href="https://github.com/dblock/garner/blob/master/lib/garner/strategies/keys/caller_strategy.rb">Garner::Strategies::Keys::Caller</a>.</p>

<a name="Cache.Invalidation"></a>
<h3>Cache Invalidation</h3>

<p>Invalidating a cache entry bound to multiple objects requires keeping an additional index along with the actual cache data. In the example above we've bound the resulting Widget to a specific <code>User</code>, the <code>Widget</code> instance itself and all instances of <code>Gadget</code>. Every time a Gadget changes, we'll want to invalidate this cache entry. Garner will handle this either automatically via a mixin (we've provided <a href="https://github.com/dblock/garner/blob/master/lib/garner/mixins/mongoid_document.rb">Garner::Mixins::Mongoid::Document</a> for the Mongoid ODM) or via an explicit <code>invalidate(Gadget)</code> call.</p>

<p>Since we're not able to scan the entire cache during invalidation, we keep a key index in the cache as well. The key for each index entry is derived from the individual elements in the binding.</p>

<a name="Using.with.Grape"></a>
<h3>Using with Grape</h3>

<p>Garner currently ships with <a href="https://github.com/dblock/garner/blob/master/lib/garner/mixins/grape_cache.rb">Garner::Mixins::Grape::Cache</a>. There're two ways to use it: <code>cache</code> and <code>cache_or_304</code>.</p>

<p>The <code>cache</code> implementation will generate a key from the binding by applying all registered cache key strategies within the current context, look up the entry by that key and either cache hit or miss. In summary, it's an extension to a standard cache, introducing a much more fully featured binding system.</p>

<pre><code class="ruby"># caches, but always returns the widget
get "widget/:id" do
  cache(bind: [Widget, params[:id]]) do
    Widget.find(params[:id])
  end
end
</code></pre>

<p>The <code>cache_or_304({ bind: [ ] })</code> will generate a meta key from the binding by applying all registered cache key strategies within the current context and search the cache index by the meta key. If a value is found, it will be compared to the ETag or the timestamp supplied in the request's <code>If-None-Match</code> or <code>If-Modified-Since</code> and issue a <code>304 Not Modified</code> where appropriate.</p>

<pre><code class="ruby"># caches, returns the widget and supports If-Modified-Since or If-None-Match
get "widget/:id" do
  cache_or_304(bind: [Widget, params[:id]]) do
    Widget.find(params[:id])
  end
end
</code></pre>

<a name="Conclusion"></a>
<h3>Conclusion</h3>

<p>An effective cache implementation for a web service combines server-side caching with client-side expiration. The latter broadly includes proxies, CDNs and browsers, all active actors in the process of exchanging information. The web is, in a way, an eventually consistent data storage and distribution system.</p>

<a name="Links"></a>
<h3>Links</h3>

<ul>
<li><a href="https://github.com/artsy/garner">Garner</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[10x Rack and Rails Output Compression with Rack::Deflater]]></title>
    <link href="http://artsy.github.io/blog/2012/02/24/10x-rack-and-rails-output-compression-with-rack-deflater/"/>
    <updated>2012-02-24T16:05:00+00:00</updated>
    <id>http://artsy.github.io/blog/2012/02/24/10x-rack-and-rails-output-compression-with-rack-deflater</id>
    <content type="html"><![CDATA[<p>You can quickly reduce the amount of data transferred from your Rack or Rails application with <a href="https://github.com/rack/rack/blob/master/lib/rack/deflater.rb">Rack::Deflater</a>. Anecdotal evidence shows a reduction from a 50Kb JSON response into about 6Kb. It may be a huge deal for your mobile clients.</p>

<p>For a Rails application, modify config/application.rb or config/environment.rb.</p>

<pre><code class="ruby config/application.rb">Acme::Application.configure do
  config.middleware.use Rack::Deflater
end
</code></pre>

<p>For a Rack application, add the middleware in config.ru.</p>

<pre><code class="ruby config.ru">use Rack::Deflater
run Acme::Instance
</code></pre>

<!-- more -->


<p>Note that the order of the middleware is very important. For example, we also use Rack::JSONP that adds automatic JSONP support to our API. It must be invoked before Rack::Deflater or it will attempt to wrap compressed content. Rack middleware is executed in reverse order [<a href="http://verboselogging.com/2010/01/20/proper-rack-middleware-ordering">source</a>].</p>

<pre><code class="ruby config/application.rb">  config.middleware.use Rack::Deflater
  config.middleware.use Rack::JSONP
</code></pre>

<p>A couple of handy RSpec tests to add to your application. You will need to modify this code with a valid API path and expected response.</p>

<pre><code class="ruby spec/api/rack_deflater_spec.rb">require 'spec_helper'

describe Rack::Deflater do
  it "produces an identical eTag whether content is deflated or not" do
    get "/api/acme"
    response.headers["Content-Encoding"].should be_nil
    etag = response.headers["Etag"]
    content_length = response.headers["Content-Length"].to_i
    get "/api/acme", {}, { "HTTP_ACCEPT_ENCODING" =&gt; "gzip" }
    response.headers["Etag"].should == etag
    response.headers["Content-Length"].to_i.should_not == content_length
    response.headers["Content-Encoding"].should == "gzip"
  end
  it "deflates JSONP content" do
    get "/api/acme?callback=parseResponse", {}, { "HTTP_ACCEPT_ENCODING" =&gt; "deflate" }
    response.headers["Content-Encoding"].should == "deflate"
    inflated_response_body = Zlib::Inflate.new(-Zlib::MAX_WBITS).inflate(response.body.to_s)
    inflated_response_body.should == "parseResponse(...)"
  end
end
</code></pre>
]]></content>
  </entry>
  
</feed>
