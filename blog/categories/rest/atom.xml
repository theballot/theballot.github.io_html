<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: rest | Artsy Engineering]]></title>
  <link href="http://artsy.github.io/blog/categories/rest/atom.xml" rel="self"/>
  <link href="http://artsy.github.io/"/>
  <updated>2018-12-16T10:16:31+00:00</updated>
  <id>http://artsy.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Is GraphQL The Future?]]></title>
    <link href="http://artsy.github.io/blog/2018/05/08/is-graphql-the-future/"/>
    <updated>2018-05-08T00:00:00+00:00</updated>
    <id>http://artsy.github.io/blog/2018/05/08/is-graphql-the-future</id>
    <content type="html"><![CDATA[<p>I have seen the future, and it looks a lot like GraphQL. Mark my words: in 5
years, newly minted full-stack app developers won’t be debating <em>RESTfulness</em>
anymore, because REST API design will be obsolete. By the end of this post, I
hope you'll see what I see in the promise of GraphQL as a new approach to
client-server interaction.</p>

<!-- more -->


<p>GraphQL is taking the full-stack world by storm. In case you’re not familiar,
GraphQL is a language-independent specification for client-server communication.
It lets you model the resources and processes provided by a server as a
<a href="https://en.wikipedia.org/wiki/Domain-specific_language">domain-specific language (DSL)</a>.
Clients can use it to send scripts written in your DSL to the server to process
and respond to as a batch.</p>

<p>That’s...different from how GraphQL’s own page describes it. GraphQL is better
known as a query language designed for clients to fetch exactly the data they
need. While this is sort of true, I would argue that GraphQL actually fails this
test in reality. It’s neither a query language, nor particularly graph-oriented.
I argue that it's <em>not</em> a query language because it comes with no native
concepts of operators and expressions that build up to queries. <em>You</em> build
whatever facilities for specifying and fulfilling queries on your own. Likewise,
if your data is a graph, it’s on you to expose that structure. But your requests
are, if anything, trees.</p>

<p>I’m not trying to be pedantic. I believe GraphQL succeeds at something subtler
and more important than literally being a graph query language. I’m writing this
piece because I kept running into difficulties approaching GraphQL from the
standpoints of REST, graph theory, or typical query languages. As I read blog
posts, StackOverflow Q&amp;As, issues on the GraphQL repo and the GraphQL spec
itself, I developed a much more nuanced understanding, which I outline below.</p>

<p>For brevity, the following assumes a intermediate familiarity with GraphQL,
including its type system, syntax, and server-side implementation. If you don’t
have this level of familiarity, I recommend going through any tutorial that
requires you to set up a GraphQL server, not just play with the query language
(which is how I ended up with a lot of misconceptions).
<a href="https://graphql.org/graphql-js/">The docs for the official JavaScript server library</a>
are a good option. I’m going to start with the basics, but only so I can put my
own spin on those concepts, not to really illustrate them with examples.</p>

<a name="A.tree.of.fetches"></a>
<h1>A tree of fetches</h1>

<p>Most applications are designed in the form of discrete pages, which are seeded
with some tiny chunk of data—say, a key or slug for some domain object—and then
perform a cascade of contingent fetches to get the data needed to populate the
templates rendered to a user. This is the basis of designing applications driven
by URL-based routing and it has been a mainstay of the MVC approach to web
application architecture for the past decade.</p>

<blockquote><p><strong>Example:</strong> At Artsy, the seed of data for rendering an artwork page could be
the slug identifying some artwork. From this slug, we need a whole bunch more
data: the metadata of the artwork, information about the artist(s), sales data
if it’s available for purchase, information about the Artsy partner that owns
it, and so on. In classic REST, this data is aggregated by a cascade of dozens
of HTTP fetches to our backend API.</p></blockquote>

<p>I wasn’t in the room when GraphQL was invented, but it seems to me that the team
that built it made a particularly crucial insight:</p>

<blockquote><p>In most cases, all of this contingent fetching forms a tree, which is more or
less <em>fixed</em> for a given page.</p></blockquote>

<p>Data from early responses contain the keys for subsequent requests, but the
linkages between these requests are usually straightforward. So if it were
possible to factor all this disparate fetching into one spot and encode it into
one big “fetching tree” data structure ahead of time, this tree could be sent to
the the server, and the server could fulfill all of the data requirements in one
shot. This cuts out a tremendous amount of wasteful chatter between client and
server. Even in today's broadband world, bandwidth and latency matter,
especially for mobile users.</p>

<a name="GraphQL.anatomy"></a>
<h1>GraphQL anatomy</h1>

<blockquote><p><strong>Editorial note</strong> I'm going to use the term "operation" pretty liberally
here, but I mean it in the conceptual sense, not in the sense of the GraphQL
spec, where it defines the semantics of an entire GraphQL request.</p></blockquote>

<p>A GraphQL request always starts with at least <em>one root API operation</em> and some
finite number of follow-ups. Idiomatically, these follow-ups are queries,
meaning that they just retrieve data, without changing the server state in
observable ways. GraphQL models API operations as <strong>fields</strong>. How a field works
in GraphQL depends on its <strong>type</strong>, which falls into one of two basic
categories:</p>

<ul>
<li><strong>Scalar</strong> types (<code>Int</code>, <code>Float</code>, <code>String</code>, <code>Boolean</code>, and <code>ID</code>, as well as
application-defined <code>enum</code> and <code>scalar</code> types) represent the individual pieces
of <em>data actually sent to the client</em>. Contrary how I think of the term scalar
in other contexts, the data can be arbitrarily complex. As far as the GraphQL
spec is concerned, scalars are just opaque blobs of data with validation and
serialization rules. As an operation, a scalar field is terminal data fetch,
with no follow-ups. They are the leaves of the request tree.</li>
<li><strong>Object</strong> types (<code>type</code>, <code>union</code> and <code>interface</code>) are collections of fields.
As an operation, an object-typed field is an intermediate operation that
serves as the junction point for follow-up operations. But, it doesn’t
directly return any data. They are the branches of the request tree.</li>
</ul>


<p>The entire model for a given API is known as its <strong>schema</strong>. Every schema has a
root query type, whose fields serve as the API’s entry points.</p>

<pre><code># The root query object type
type Query {
  artwork(id: ID): Artwork
  artist(name: String)
  # … a whole bunch more root fields
}

type Artwork {
  title: String
  artist: Artist
}

type Artist {
  name: String
}
</code></pre>

<p>A GraphQL query request begins by mentioning at least one of the fields of the
root query object. This represents an initial query. And if that field is an
object, <em>its</em> fields are used to specify any number of follow-up queries.
Critically, <em>any</em> field in the request tree can take arguments, allowing a
request to be parameterized at all depths.</p>

<p>Take this query, for example:</p>

<pre><code>{
  artwork(id: "andy-warhol-campbells-soup-i-black-bean") {
    title
    artist {
      name
    }
  }
}
</code></pre>

<p>Here, we tell the server to look up an <code>Artwork</code> by its slug, and tell us the
title. So far, this is just like REST. But we <em>also</em> tell it to find us the
<code>Artist</code> for us. Importantly, object fields <em>must</em> be followed up with further
queries, and scalar fields <em>cannot</em> be. With that in mind, it’s easy to see that
<code>artwork</code> and <code>artist</code> are object fields, while <code>title</code> and <code>name</code> are scalar
fields.</p>

<p>Also note that the fact that there’s also an <code>artist</code> root query field actually
has nothing to do with its presence under <code>Artwork</code>. There can be multiple paths
to reach the same GraphQL type. This is defined explicitly by the schema.</p>

<p>Usefully, the server’s response to a GraphQL request will directly mirror the
shape of the request itself. The result of the request above looks like:</p>

<pre><code>{
  "data": {
    "artwork": {
      "title": "Campbell's Soup I: Black Bean",
      "artist": {
        "name": "Andy Warhol"
      }
    }
  }
}
</code></pre>

<a name="GraphQL.as.a..meta-.scripting.language"></a>
<h1>GraphQL as a (meta-)scripting language</h1>

<p>Let’s dig a little deeper into the scripting language interpretation of GraphQL,
because this is the crux of how I think people should think of GraphQL. If I
were to guess, I think Facebook…</p>

<ul>
<li>…knows this is true. After all, much of the spec is devoted to
<a href="http://facebook.github.io/graphql/October2016/#sec-Execution">the execution model of GraphQL</a>.</li>
<li>…might have backed into this design. It’s well known that they think of their
data as a graph, so I suspect GraphQL might have begun literally as a "graph
query language", analogous to <a href="https://en.wikipedia.org/wiki/SQL">SQL</a> for
relational databases.</li>
<li>…thinks that this too difficult to explain, and thus, settled on the query
language paradigm.</li>
</ul>


<p>There are a couple reasons GraphQL might not look like a scripting language to
you. It didn’t to me, at first! After all, you don't write your request as list
of statements. It doesn’t have a concept of variables, other than parameters to
the whole document. There are no looping constructs or recursion. But I think a
closer look might shift your perspective.</p>

<a name="Control.flow"></a>
<h2>Control flow</h2>

<p>It’s true that a GraphQL request doesn’t follow the same vertical sequence of
steps model familiar to most programming languages. But sequencing <em>does</em> exist.
It’s just represented by calling nested fields of object types, terminating in a
scalar field. See this request:</p>

<pre><code>{
  step1(arg: “something”) {
    step2 {
      step3(arg: "something else”) {
        outputScalar
      }
    }
  }
</code></pre>

<p>In a more traditional language, this would look more like:</p>

<pre><code>step1(“something”)
step2()
return step3(“something else”)
</code></pre>

<p>So, sequencing got a bit more verbose, but it <em>is</em> there.</p>

<p>Interestingly, GraphQL reserves vertical stacking for something that’s an
afterthought in most languages: <em>concurrency</em>. (Granted, there’s no way to
<a href="https://en.wikipedia.org/wiki/Synchronization_(computer_science)">synchronize</a>
concurrent paths of execution.) I’m not going to quote
<a href="https://facebook.github.io/graphql/October2016/">the spec</a>, but search it
yourself, and you can find the word “parallel” in there several times. This
design is intentional.</p>

<a name="Variables"></a>
<h2>Variables</h2>

<p>One of the core aspects of programming is the ability to pass intermediate data
around. The most basic way languages accomplish this is with named variables.
Many languages allow variables to be reassigned; some don't. GraphQL doesn’t
have them at all! But that doesn’t mean data can’t be propagated.</p>

<p>GraphQL supports one kind of propagation, which is the propagation of context
down the sequence of resolvers. It happens implicitly and invisibly. Exactly
what data is propagated and what that means is up to you.</p>

<p>How does this work? Well, if you have worked on GraphQL server code, you know
that every field has a <strong>resolver</strong>.</p>

<ul>
<li>For scalar fields, the resolver is responsible for returning the actual data
that the client sees.</li>
<li>For object fields, the resolver instead returns a hidden chunk of data that is
forwarded along to the resolvers of the fields contained in the object. So
these resolvers get their parent object’s hidden data, the global context, and
any arguments, and they can use all of these values to produce their value.</li>
</ul>


<p>Often, we just resolve an object field to a domain object. Its scalar fields
might correspond to properties of that domain object and its object fields might
correspond to related objects. But the architecture is more powerful than this!
A deeply nested field can potentially be the result of the resolved values of
all its parents. It all depends on how you design your resolvers to work
together.</p>

<p>This pattern reminds me a bit of when <a href="https://api.jquery.com/">jQuery</a> first
clicked for me. A lot of details are propagated invisibly within your <code>jquery</code>
object as you chain method calls to refine your DOM selections.</p>

<a name="Looping.and.recursion"></a>
<h2>Looping and recursion</h2>

<p>GraphQL doesn’t have them, plain and simple. Consequently, the GraphQL DSLs you
design are not
<a href="https://en.wikipedia.org/wiki/Turing_completeness">Turing-complete</a>--they will
always halt in a finite amount of steps. This is really important, because it
prevents clients from being able to send servers on errands that will never end.
Of course, the <em>implementations</em> of field resolvers on the server are free to do
whatever they want in full Turing-complete glory.</p>

<a name="Putting.it.together"></a>
<h2>Putting it together</h2>

<p>My point here is that the execution model of GraphQL is in many ways just like a
scripting language interpreter. The limitations of its model are strategic, to
keep the technology focused on client-server interaction. What's interesting is
that you as a developer provide nearly all of the definition of what operations
exist, what they mean, and how they compose. For this reason, I consider GraphQL
to be a <em>meta-scripting language</em>, or, in other words, a toolkit for building
scripting languages.</p>

<a name="The.post-REST.world"></a>
<h1>The post-REST world</h1>

<p>Subtly, this paradigm is a sharp step away from a whole body of knowledge that
models APIs as resources with fixed verbs, which we know as REST. It’s more
appropriate to think of GraphQL requests as a script of remote procedure calls
(RPC). From this perspective, the design of the schema is a lot less about data
modeling than it is a question of how you want your entire API to be traversed.
This encourages a verb-oriented mindset.</p>

<a name="Verb.orientation"></a>
<h2>Verb orientation</h2>

<p>Speaking of verbs, you can think of "fetch" as being the default verb in
GraphQL. You model other verbs as <strong>mutations</strong>. I delayed learning about
mutations, because I thought they must be way more complex than queries. Quite
the opposite! They all sit in one big, flat bucket at the root of your schema,
as the fields of the root <code>mutation</code> type. These fields have a type too, and if
it is an object type, then you can issue effectively any number of follow-up
queries after your mutation completes. Learning about mutations was when it
really dawned on me that <em>fields are just function calls</em>.</p>

<p>Mutations are a major break with REST. In GraphQL, your mutations are defined
under root mutation object that is separate from your root query object.
Therefore, you are immediately asked to accept that they don't represent verbs
on a resource, but verbs <em>on your entire service</em>. This eliminates one of REST’s
key weak points, namely that complex operations that touch multiple parts of an
application’s data model are difficult to model as a PUT, DELETE, POST, or PATCH
on a single resource. In my experience, this "impedance mismatch” between API
modeling and domain modeling has led to the worst aspects of my HTTP API
designs.</p>

<a name="REST.is.dead..Long.live.REST."></a>
<h2>REST is dead. Long live REST!</h2>

<p>It is borderline heresy in some circles to suggest that REST API design is dead.
But I’m saying it. Don’t get me wrong, REST is still a great paradigm for
serving static assets. It’s the <em>API</em> part I have an issue with.</p>

<p>Ironically, I think there’s a strong argument that a GraphQL request document
maps very nicely to the concept of a resource:</p>

<ul>
<li>It doesn’t change that often, and you could PUT it to store it, perhaps using
a hash of the request document to form the URL.</li>
<li>GraphQL queries map elegantly to GET operations on a stored query request
document’s URL.</li>
<li>GraphQL mutations map decently to POST operations to a stored mutation request
document’s URL.</li>
<li>The arguments of a GraphQL request map elegantly to HTTP query parameters.</li>
</ul>


<p>In other words, GraphQL is simply another formalization layer of HTTP-based API
design. Think of it as being akin to the way JSON representation changed the way
we think about client-server communication in full-stack apps. It’s not so much
that REST will cease to exist, but that it will fade to the background, as an
implementation detail of GraphQL application frameworks.</p>

<a name="GraphQL.is.not.your.data.model"></a>
<h1>GraphQL is not your data model</h1>

<p>Another realization I’ve had in learning to apply GraphQL is that the schema is
<em>not</em> the actual data model, and therefore raw GraphQL responses cannot be
directly used by the client. You <em>could</em> choose to think of it this way, but
you’re likely to run into some conundrums:</p>

<ul>
<li><a href="https://github.com/facebook/graphql/issues/101">There is no free-form map data structure</a>.
There are only objects with fixed fields, scalars, and lists.</li>
<li>It is difficult to design abstractions over types.</li>
<li>The object tree you get in return from a query request is neither normalized
nor is it an object graph (multiple copies of the same object may be
returned).</li>
<li>Commonly used protocol patterns, like
<a href="https://facebook.github.io/relay/docs/graphql-connections.html">the connection pattern</a>,
require explicit modeling within your schema.</li>
<li>The limitations of GraphQL's type system make certain modeling techniques
difficult to directly model, such as
<a href="https://stackoverflow.com/questions/47933512/representing-enum-object-variant-type-in-graphql">singletons within unions</a>.</li>
<li>Recursive data types can’t be queried to undefined depth in their nested form.
Think of your comment board with nested replies.</li>
</ul>


<p>The upshot of this is that there likely needs to be some process of conversion
from your native data model on your server to your GraphQL API, and then again
from your client’s API consumption code to its internal data model.
<a href="https://facebook.github.io/relay/">Relay</a> and
<a href="https://www.apollographql.com/client">Apollo</a> serve this purpose. Their utility
wasn’t immediately clear to me when I naively imagined GraphQL to literally be a
system for reproducing a slice of server-side object graph. (Hmm, where might I
have gotten that impression from?)</p>

<p>A lot of discussion in the GraphQL space centers on data modeling—the nouns.
There’s a lot of debate and worthwhile work to be done on that front, but one of
my primary reasons for writing this piece is to think about the verbs. What
happens when you think of GraphQL requests as not just verbs, but <em>chains</em> of
verbs? My inkling is that you start to be able to represent services in a much
more fluid way. Complex processes no longer have to be orchestrated by API
clients or hidden behind unwieldy black-box POST endpoints. Instead, clients can
compose processes from the easily inspectable building blocks that the server
provides via its GraphQL schema. That’s a whole different approach to API
design.</p>

<a name="So..where.to.now."></a>
<h1>So, where to now?</h1>

<p>I began by asserting that the future looks a lot <em>like</em> GraphQL. But I did not
say that GraphQL <em>is the future</em>. I hedge because there are a lot of unanswered
questions and some pain points within today’s GraphQL, even as it paints a
compelling picture of the future. I may write a follow-up piece bringing up some
of these gripes. At the moment, Facebook still largely controls the development
of the technology and it has been slow to evolve. Arguably, this is a good
thing, as the full-stack community continues to digest the basic concepts. But
I’m sure impatient folks will attempt forks or create parallel technologies. How
it all balances out is anybody’s guess.</p>

<p>Nonetheless, today’s GraphQL is already a tremendous leap forward from REST API
design. It much more directly models the sort of data traversals a client needs
to perform in order to do its job. I expect significant refinement within this
space over the next couple years. And after a couple more, the days before
GraphQL will be just another source of lore for grizzled vets like us.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RESTful API Caching with Garner]]></title>
    <link href="http://artsy.github.io/blog/2012/05/30/restful-api-caching-with-garner/"/>
    <updated>2012-05-30T21:21:00+00:00</updated>
    <id>http://artsy.github.io/blog/2012/05/30/restful-api-caching-with-garner</id>
    <content type="html"><![CDATA[<p>Implementing server-side RESTful API caching is hard. In a straightforward API all the expiry decisions can be made automatically based on the URL, but most real world APIs that add requirements around object relationships or user authorization make caching particularly challenging.</p>

<p>At <a href="http://goruco.com/">GoRuCo</a> we open-sourced <a href="http://github.com/artsy/garner">Garner</a>, a cache implementation of the concepts described in this post. To "garner" means to gather data from various sources and to make it readily available in one place, kind-of like a cache! Garner works today with the <a href="http://github.com/intridea/grape">Grape API framework</a> and the <a href="http://github.com/mongoid/mongoid">Mongoid ODM</a>. We encourage you to fork the project, extend our library to other systems and contribute your code back, if you find it useful.</p>

<p>Garner implements the Artsy API caching cookbook that has been tried by fire in production.</p>

<!-- more -->


<a name="Enabling.Caching.of.Static.Data"></a>
<h3>Enabling Caching of Static Data</h3>

<p>Caching static data is fairly easy: set <code>Cache-Control</code> and <code>Expires</code> headers in the HTTP response.</p>

<pre><code class="ruby">expire_in = 60 * 60 * 24 * 365
header "Cache-Control", "private, max-age=#{expire_in}"
header "Expires", CGI.rfc1123_date(Time.now.utc + expire_in)
</code></pre>

<p>This example indicates to a cache in front of your service (CDN, proxy or user's browser) that the data expires in a year and that it's private for this user. When caching truly static data, such as images, use <code>public</code>. Your CDN or proxy, such as <a href="https://www.varnish-cache.org/">Varnish</a> that sits in front of Artsy on <a href="http://www.heroku.com/">Heroku</a>, will cache the data and subsequent requests won't even need to hit your server, even though it could potentially serve different content every time.</p>

<a name="Disabling.Caching.of.Dynamic.Data"></a>
<h3>Disabling Caching of Dynamic Data</h3>

<p>Caching dynamic data is slightly more involved. Let's begin with a simple Ruby API that returns a counter.</p>

<pre><code class="ruby">class API &lt; Grape::API
  def count
    { count : 0 }
  end
end
</code></pre>

<p>This kind of dynamic data cannot have a well-defined expiration time. The counter may be incremented at any time via another API call or process, so we must tell the client not to cache it. This is accomplished by setting the value of <code>Cache-Control</code> to <code>private, max-age=0, must-revalidate</code>. The <code>private</code> option instructs the client that it's allowed to store data in a private cache (unnecessary, but is known to work around overzealous cache implementations), <code>max-age</code> that it must check with the server every time it needs this data and <code>must-revalidate</code> prevents gateways from returning a response if your API server is unreachable. An additional <code>Expires</code> header set to a past date (usually January 1st 1990), will make double-sure the entire request expires immediately with old browsers.</p>

<p>Garner provides <a href="https://github.com/dblock/garner/blob/master/lib/garner/middleware/cache/bust.rb">Garner::Middleware::Cache::Bust</a> a Rack middleware that accomplishes just that.</p>

<a name="If-Modified-Since..ETags.and.If-None-Match"></a>
<h3>If-Modified-Since, ETags and If-None-Match</h3>

<p>Given our API example, a client may want to retrieve the value of the counter and, for example, run a job every time the value changes. As it stands, the current API requires an effort on the client's part to remember the previous value and compare it every time it makes an API call. This can be avoided by asking the server for a new counter if the value has changed since last time it was retrieved.</p>

<p>One option for the client is to include an <code>If-Modified-Since</code> header with a timestamp. The server could then choose to respond with <code>304 Not Modified</code> if the counter hasn't changed since the timestamp in <code>If-Modified-Since</code>. While this may be acceptable for certain data, timestamps have a granularity of seconds. A counter may be modified multiple times during the same second, therefore preventing it from retrieving the result of the second modification.</p>

<p>A more robust solution is to generate a unique signature, called ETag, for this data and to use it to find out whether the counter has changed. There exists a generic <a href="https://github.com/rack/rack/blob/master/lib/rack/etag.rb">Rack::ETag</a> middleware that sets ETags on all text bodies. Adding the middleware would produce an ETag for every response from the API. You can now combine <code>Rack::ETag</code> and <code>Rack::Cache</code> - a client makes a request with an <code>If-None-Match: Etag</code> header and the server returns a <code>304 Not Modified</code> if the data hasn't changed, without sending the data.</p>

<a name="Memcached.via.Dalli.and.Rails.Cache"></a>
<h3>Memcached via Dalli and Rails.Cache</h3>

<p>There's an obvious problem with <code>Rack::Cache</code>. In order for it to serve a <code>304 Not Modified</code> response it must compare the ETag from the request with the ETag generated from the body of the current response. So it saves bandwidth, but doesn't save execution time on the server. We'd also like the server to cache the entire response and therefore avoid any heavy processing, such as querying a database.</p>

<p>A typical Ruby cache supports a block syntax. The following example returns a cached copy when available or executes the supplied block and stores the result in the cache. In this context <code>cache</code> could be <code>Rails.cache</code> or an instance of <code>ActiveSupport::Cache::FileStore</code>. We use <code>Rails.cache</code> with <a href="http://memcached.org/">Memcached</a> via the <a href="https://github.com/mperham/dalli">dalli gem</a> in production.</p>

<pre><code class="ruby">cache("count") do
  { count : 0 }
end
</code></pre>

<p>The parameter of the <code>cache</code> call is the cache key that uniquely identifies the cache entry. Hard-coding cache keys is tedious, so we can generate a key from the API version, route and request parameters.</p>

<pre><code class="ruby">def cache_key
  options = { }
  options[:version] = version
  options[:path] = request.path
  options[:params] = request.GET
  Digest::MD5.hexdigest(options.to_json)
end
</code></pre>

<p>This generic approach to key generation is fine to get one started, but is largely insufficient for real-world applications.</p>

<a name="Production-Grade.Cache.Keys.and.Model.Binding"></a>
<h3>Production-Grade Cache Keys and Model Binding</h3>

<p>Most large scale web properties operate on data with the following requirements.</p>

<ul>
<li>Partition cache in sync with object ownership and permissions. For example, a <code>Widget</code> may have different representations depending on whether <code>current_user</code> owns it or not or may choose to return a <code>401 Access Denied</code> in some of the cases.</li>
<li>Retrieve objects from cache no matter where the calling code appears. The above strategy would generate identical keys from two different locations within the same function.</li>
<li>Invalidate entire cached collections when one of the objects in a collection has changed. For example, invalidate all cached instances of <code>Widget</code> when a new <code>WidgetCategory</code> is created and forces a reorganization of those widgets.</li>
</ul>


<p>Garner will help you introduce such aspects of your domain model into the cache and solve all these.</p>

<p>A cache is a collection of flat name/value pairs. We'll specify object relationships within each key by chaining model names, field values and by using wildcards where appropriate. For example, <code>User/id=12,Widget/id=45,Gadget/*</code> binds the cache value to changes in <code>User</code> with id=12, <code>Widget</code> with id=45 and any instance of <code>Gadget</code>.</p>

<pre><code class="ruby">cache(bind: [[User, { id: current_user.id }], [Widget, { id: params[:widget_id] }], [Gadget] ])
  Widget.where({ id: params[:widget_id], user_id: current_user.id }).first.as_json
end
</code></pre>

<p>Binding to multiple objects or classes can also be reasoned about as a way to partition the cache. Adding structure into the fields lets us reason about the relationships between various instances of data in the cache.</p>

<a name="Role-Based.Caching"></a>
<h3>Role-Based Caching</h3>

<p>Role-Based caching is a subset of the generic problem of binding data to groups of other objects. For example, a <code>Widget</code> may have a different representation for an <code>admin</code> vs. a <code>user</code>. In Garner you can inject something called a "key strategy" into the current key generation pipeline. A strategy is a plain module that must implement two methods: <code>field</code> and <code>apply</code>. The former should define a unique key name and the latter applies the strategy within a context.</p>

<p>The following example introduces the role of the current user into the cache key.</p>

<pre><code class="ruby">module MyApp
  module Garner
    module RoleStrategy
      class &lt;&lt; self
        def field
          :role
        end
        def apply(key, context = {})
          key.merge { :role =&gt; current_user.role }
        end
      end
    end
  end
end
</code></pre>

<p>Garner key strategies can be currently set at application startup time.</p>

<pre><code class="ruby">Garner::Cache::ObjectIdentity::KEY_STRATEGIES = [
  Garner::Strategies::Keys::Caller, # support multiple calls from the same function
  MyApp::Garner::RoleStrategy, # custom strategy for role-based access
  Garner::Strategies::Keys::RequestPath # injects the HTTP request's URL
]
</code></pre>

<a name="Multiple.Calls.from.the.Same.Function"></a>
<h3>Multiple Calls from the Same Function</h3>

<p>Binding to the same set of objects within the same function call will produce the same key. To solve this in a generic way we can examine the call stack, find the caller that's not within the helper module and inject it in the key options.</p>

<pre><code class="ruby">api_caller = caller.detect { |line| !(line =~ /\/#{File.basename(__FILE__)}/) }
api_caller_line = api_caller.match(/(.*\.rb:[0-9]*):/) if api_caller
options[:caller] = api_caller_line[1] if api_caller_line
</code></pre>

<p>Garner implements this as <a href="https://github.com/dblock/garner/blob/master/lib/garner/strategies/keys/caller_strategy.rb">Garner::Strategies::Keys::Caller</a>.</p>

<a name="Cache.Invalidation"></a>
<h3>Cache Invalidation</h3>

<p>Invalidating a cache entry bound to multiple objects requires keeping an additional index along with the actual cache data. In the example above we've bound the resulting Widget to a specific <code>User</code>, the <code>Widget</code> instance itself and all instances of <code>Gadget</code>. Every time a Gadget changes, we'll want to invalidate this cache entry. Garner will handle this either automatically via a mixin (we've provided <a href="https://github.com/dblock/garner/blob/master/lib/garner/mixins/mongoid_document.rb">Garner::Mixins::Mongoid::Document</a> for the Mongoid ODM) or via an explicit <code>invalidate(Gadget)</code> call.</p>

<p>Since we're not able to scan the entire cache during invalidation, we keep a key index in the cache as well. The key for each index entry is derived from the individual elements in the binding.</p>

<a name="Using.with.Grape"></a>
<h3>Using with Grape</h3>

<p>Garner currently ships with <a href="https://github.com/dblock/garner/blob/master/lib/garner/mixins/grape_cache.rb">Garner::Mixins::Grape::Cache</a>. There're two ways to use it: <code>cache</code> and <code>cache_or_304</code>.</p>

<p>The <code>cache</code> implementation will generate a key from the binding by applying all registered cache key strategies within the current context, look up the entry by that key and either cache hit or miss. In summary, it's an extension to a standard cache, introducing a much more fully featured binding system.</p>

<pre><code class="ruby"># caches, but always returns the widget
get "widget/:id" do
  cache(bind: [Widget, params[:id]]) do
    Widget.find(params[:id])
  end
end
</code></pre>

<p>The <code>cache_or_304({ bind: [ ] })</code> will generate a meta key from the binding by applying all registered cache key strategies within the current context and search the cache index by the meta key. If a value is found, it will be compared to the ETag or the timestamp supplied in the request's <code>If-None-Match</code> or <code>If-Modified-Since</code> and issue a <code>304 Not Modified</code> where appropriate.</p>

<pre><code class="ruby"># caches, returns the widget and supports If-Modified-Since or If-None-Match
get "widget/:id" do
  cache_or_304(bind: [Widget, params[:id]]) do
    Widget.find(params[:id])
  end
end
</code></pre>

<a name="Conclusion"></a>
<h3>Conclusion</h3>

<p>An effective cache implementation for a web service combines server-side caching with client-side expiration. The latter broadly includes proxies, CDNs and browsers, all active actors in the process of exchanging information. The web is, in a way, an eventually consistent data storage and distribution system.</p>

<a name="Links"></a>
<h3>Links</h3>

<ul>
<li><a href="https://github.com/artsy/garner">Garner</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
