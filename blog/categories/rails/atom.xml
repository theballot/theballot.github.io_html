<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: rails | Artsy Engineering]]></title>
  <link href="http://artsy.github.io/blog/categories/rails/atom.xml" rel="self"/>
  <link href="http://artsy.github.io/"/>
  <updated>2018-12-16T10:16:31+00:00</updated>
  <id>http://artsy.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Switch from Capybara Webkit to Chrome]]></title>
    <link href="http://artsy.github.io/blog/2018/11/27/switch-from-capybara-webkit-to-chrome/"/>
    <updated>2018-11-27T00:00:00+00:00</updated>
    <id>http://artsy.github.io/blog/2018/11/27/switch-from-capybara-webkit-to-chrome</id>
    <content type="html"><![CDATA[<p>Volt is the internal app name of Artsy CMS, and our partners use it to manage their inventory and presence on artsy.net. It's a Rails-based UI app that talks to many API services. We use <a href="https://github.com/rspec/rspec">RSpec</a> extensively to cover controller, model, view, and feature specs. As of Jun. 2018, Volt had 3751 specs and 495 of them were run with JavaScript enabled. It took about 16 mins to run on CircleCI with 6x parallelism.</p>

<p>Capybara-webkit was introduced from the very beginning of Volt for testing JavaScript-enabled specs via headless WebKit browser. It's been providing a lot of confidence for the past 4+ years; however, a few reasons/growing concerns have encouraged us to look for (more modern) alternatives:</p>

<!-- more -->


<a name="The.Problem"></a>
<h2>The Problem</h2>

<ul>
<li>The <a href="https://github.com/thoughtbot/capybara-webkit/tree/v1.14.0#qt-dependency-and-installation-issues">dependency of specific versions of Qt</a> has been causing frustrations to set it up properly both on engineers' local machines and on CI.</li>
<li>The roadmap of capybara-webkit development is <a href="https://github.com/thoughtbot/capybara-webkit/issues/885#issuecomment-193988527">unclear</a>.</li>
<li>It's been hard to truly identify the root cause of "flickering" feature specs (i.e. tests that fail intermittently and are hard to reliably reproduce), while retrying tended to resolve it on CI.</li>
<li>The entire RSpec tests took about 16 mins to complete on CI, with 6 parallelism. The slowness made it unrealistic to run the whole tests locally.</li>
</ul>


<a name="The.Goal"></a>
<h2>The Goal</h2>

<p>Headless Chrome has gained a lot of attention in the past years and migrations done by companies such as <a href="https://about.gitlab.com/2017/12/19/moving-to-headless-chrome/">GitLab</a> and <a href="https://robots.thoughtbot.com/headless-feature-specs-with-chrome">thoughtbot</a> have proved it to be a promising alternative to capybara-webkit. In fact, it's been <a href="http://guides.rubyonrails.org/5_1_release_notes.html#system-tests">officially included in Rails 5.1</a> for <a href="https://guides.rubyonrails.org/testing.html#system-testing">system tests</a>.</p>

<p>The goal of this project is to switch to Headless Chrome and maintain the same feature sets we have now. This includes:</p>

<ul>
<li>Making all existing specs pass</li>
<li>Running in container environments and using Artsy <a href="https://github.com/artsy/hokusai">Hokusai</a></li>
<li>Supporting mechanisms to debug specs, e.g. examining browser console logs for JavaScript behavior, taking screenshots on demand and automatically on failure, etc.</li>
<li>Bonus point to improve the stability of feature specs</li>
<li>Bonus point to improve the speed of running the entire test suite</li>
</ul>


<a name="The.How"></a>
<h2>The How</h2>

<p>First, we replaced <code>capybara-webkit</code> with <code>selenium-webdriver</code> and <code>chromedriver-helper</code>:</p>

<pre><code class="ruby">gem 'selenium-webdriver'
gem 'chromedriver-helper'
</code></pre>

<p><a href="https://github.com/flavorjones/chromedriver-helper"><code>chromedriver-helper</code></a> was useful to help install <a href="https://sites.google.com/a/chromium.org/chromedriver/">chromedriver</a> in different environments, e.g. an engineer's local machine, CI, etc.</p>

<p>Second, we registered both <code>:chrome</code> and <code>:headleass_chrome</code> drivers. By default, it used Headless Chrome as the JavaScript driver, and we could easily switch to Chrome and observe the actual interaction happening in a real browser.</p>

<pre><code class="ruby">Capybara.register_driver :chrome do |app|
  Capybara::Selenium::Driver.new(app, browser: :chrome)
end

Capybara.register_driver :headless_chrome do |app|
  caps = Selenium::WebDriver::Remote::Capabilities.chrome(loggingPrefs: { browser: 'ALL' })
  opts = Selenium::WebDriver::Chrome::Options.new

  chrome_args = %w[--headless --window-size=1920,1080 --no-sandbox --disable-dev-shm-usage]
  chrome_args.each { |arg| opts.add_argument(arg) }
  Capybara::Selenium::Driver.new(app, browser: :chrome, options: opts, desired_capabilities: caps)
end

Capybara.configure do |config|
  # change this to :chrome to observe tests in a real browser
  config.javascript_driver = :headless_chrome
end
</code></pre>

<p>We were on Rails v5.0.2 and Capybara v2.18.0 during the migration. We will be able to simplify the configuration by using the default <code>:selenium_chrome</code> and <code>:selenium_chrome_headless</code> drivers introduced in <a href="https://github.com/teamcapybara/capybara/blob/3.11.1/lib/capybara.rb#L535-L545">Capybara v3.11.1</a>. In addition, Rails v5.1 introduced the new system tests, and it'll be even simpler by using the <a href="https://api.rubyonrails.org/v5.1.3/classes/ActionDispatch/SystemTestCase.html#method-c-driven_by"><code>driven_by</code></a> method.</p>

<a name="Lessons.Learned"></a>
<h2>Lessons Learned</h2>

<p>Naively switching to Headless Chrome caused about 60 spec failures on my local machine. We simply went through them one by one and fixed them. A big part of failures was due to <a href="https://github.com/thoughtbot/capybara-webkit/tree/v1.14.0#non-standard-driver-methods">capybara-webkit's non-standard driver methods</a>, such as setting cookies, inspecting console logs, etc., and we just had to migrate to Selenium WebDriver's equivalents.</p>

<p>However, we still observed flickering specs on CI, while the exact failures seemed to be different than previously observed with Capybara Webkit. We will have to investigate farther for possible causes. Regarding speed, we didn't see significant improvement after switching to Headless Chrome, as mentioned in GitLab's and others' blog post, too.</p>

<a name="Next.Steps"></a>
<h2>Next Steps</h2>

<p>The naive migration to Chrome (and removal of the Qt dependency) already improved the developer experience quite a lot (e.g. no more wrestling with installing Capybara Webkit and Qt 5.5 on every engineer's local machine <em>and</em> CI.) There are many next steps we can keep experimenting with and improving our tests, for example</p>

<ul>
<li>Updating Volt to Rails >= 5.1 and switching to system tests</li>
<li>Investigating the causes of the flickering specs by looking into intermittent failures reported on CI</li>
<li>Improving speed by using Docker <a href="https://docs.docker.com/develop/develop-images/multistage-build/">multi-stage builds</a>, caching, writing the right type and amount of tests, etc.</li>
</ul>


<p>It's a long journey, and we were all excited about the migration and the new future. We'd love to hear your experience, too!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How hard could it be to create an email?]]></title>
    <link href="http://artsy.github.io/blog/2018/11/19/mjml/"/>
    <updated>2018-11-19T00:00:00+00:00</updated>
    <id>http://artsy.github.io/blog/2018/11/19/mjml</id>
    <content type="html"><![CDATA[<!-- OUTLINE -->


<p>Let's talk about email HTML.</p>

<p>If you've never worked on emails before, you might think the process works something like this:</p>

<ol>
<li>Write some HTML, but maybe with a few more tables than you usually use since emails like those.</li>
<li>Render it in your browser. Nice! Looking great.</li>
<li>Send yourself a quick test. Just like in your browser! Sweet!</li>
<li>Send that PR and move on to the next thing.</li>
</ol>


<p><img src="/images/2018-11-19-mjml/example.png" alt="/images/2018-11-19-mjml/example.png" /></p>

<p>In reality, it's more like this:</p>

<ol>
<li>Write some HTML with more tables than you think could possibly be necessary. There's no way it'll break with all
these tables, right?</li>
<li>Render it in the browser. Cool, looks fine.</li>
<li>Send yourself a test, and send one to a service like <a href="https://www.litmus.com">Litmus</a> or
<a href="https://www.emailonacid.com">Email on Acid</a> that renders the email in dozens of clients</li>
<li>Looking good in Gmail...good in Apple mail...wait why is it completely broken in Outlook 2007 (and 2010, 2013,
and 2019)? And Yahoo Mail on Internet Explorer? Shoot.</li>
<li>Better add some more tables. That's usually the solution.</li>
<li>Well...that didn't work. Find a post from 2009 in a forum for Netscape enthusiasts that implies you might want
to add an extra Outlook-only table using <code>&lt;!--[if mso | IE]&gt;</code> with
<code>role="presentation" and cellpadding="0" cellspacing="0"</code>. Maybe that'll work.</li>
<li>Outlook 2007 is fixed! Nice! Oh...but now it looks broken on iPhones. Back to the drawing board.</li>
</ol>


<p><img src="/images/2018-11-19-mjml/outlook-2019-broken.png" alt="/images/2018-11-19-mjml/outlook-2019-broken.png" /></p>

<!-- more -->


<p>And after a few hours, you've probably squished most bugs on most clients and are ready to ship it, but also ready
to tear your hair out. Creating emails that render gracefully in clients that were built 15 years ago and in
clients that were built this year isn't easily done. That's where MJML comes in.</p>

<a name="What.is.MJML."></a>
<h2>What is MJML?</h2>

<p><a href="https://mjml.io">MJML</a>, short for Mailjet Markup Language, is a markup language that is written like simplified HTML/CSS
and renders email-friendly, responsive HTML. So instead of having to code a few thousand lines of complex HTML, you
code a couple hundred lines of MJML, and it outputs code that looks good on <em>every single client</em>.</p>

<pre><code class="html">&lt;mjml&gt;
  &lt;mj-head&gt;
    &lt;!-- global styles --&gt;
    &lt;mj-attributes&gt;
      &lt;mj-text
        font-family="HelveticaNeue, Helvetica, Arial, sans-serif"
        font-size="14px"
        line-height="21px"
        padding="0"
      /&gt;
      &lt;mj-section padding="0" /&gt;
    &lt;/mj-attributes&gt;
  &lt;/mj-head&gt;
  &lt;mj-body width="450px" background-color="#fff"&gt;
    &lt;mj-section padding="20px" border="1px solid #e5e5e5"  border-bottom="0"&gt;
      &lt;mj-group&gt;
        &lt;mj-column vertical-align="middle" width="19%"&gt;
          &lt;mj-image width="66px" align="left" padding="0" src="jared-french-prose.png"/&gt;
        &lt;/mj-column&gt;
        &lt;mj-column padding-left="20px" vertical-align="middle" width="81%"&gt;
          &lt;mj-text&gt;Order #B135790&lt;/mj-text&gt;
          &lt;mj-text&gt;Jared French&lt;/mj-text&gt;
          &lt;mj-text&gt;Prose, ca. 1948&lt;/mj-text&gt;
        &lt;/mj-column&gt;
      &lt;/mj-group&gt;
    &lt;/mj-section&gt;
  &lt;/mj-body&gt;
&lt;/mjml&gt;
</code></pre>

<p>Looking good in Outlook 2007:
<img src="/images/2018-11-19-mjml/outlook-2007-fixed.png" alt="/images/2018-11-19-mjml/outlook-2007-fixed.png" /></p>

<p>It feels pretty magical.</p>

<p>When the marketing team was getting ready to revamp our user-facing emails in summer 2017, we found MJML and
thought, "hey, this could make life a lot simpler in the long run." It took some time to get comfortable with it,
but maybe not as much as you'd think due to its similarities with HTML.</p>

<p>It can be tricky figuring out how to accomplish something really, really specific in MJML. Our design team sent
over templates with pretty specific needs—mobile vs. desktop padding, for example, and it took us a while to learn
how to make those types of tricky changes (though still less time than it would have taken in raw HTML, I'm sure).</p>

<a name="Limitations"></a>
<h2>Limitations</h2>

<p>Of course, MJML is still limited by the boundaries of email clients. It can't make gifs render in old versions of
Outlook, or fix the way Lotus Notes ignores stated image widths in favor of actual widths. We've run into issues
with background images that MJML couldn't completely alleviate on all clients (they're pretty poorly supported),
and because lots of mobile clients don't support media queries, we've had to develop in a way that makes sure our
desktop layouts and sizes will look good on small screens.</p>

<p>And it's worth noting that the HTML file output by MJML is going to be large. On our biggest emails, the ones
featuring articles, artists, artworks, events, ads, and more, we've had to deal with clipping by minifying our
output (which comes with its own share of difficulties, since again, things that work fine when minifying for web
will break email clients). If you're curious, we use the <a href="http://kangax.github.io/html-minifier/">Kangax Minifier</a>
with <a href="/images/2018-11-19-mjml/kangax-settings.png">these particular settings</a>.</p>

<p>One thing that's helped tremendously with these issues is MJML's great
<a href="https://slacking-inviter.herokuapp.com/">Slack community</a>. Both the devs of MJML and several avid users (including
both of us) are good about answering questions from new and seasoned users alike.</p>

<a name="Bringing.MJML.to.Engineering"></a>
<h2>Bringing MJML to Engineering</h2>

<p>Part of what the email marketing team appreciated about MJML is that it could be written by someone who just knew
HTML and CSS—you don't have to be an experienced programmer to make it work. The engineering team wasn't much
involved with the development of the Marketing team's emails in MJML, but when they began working on new
transactional emails for <a href="https://www.artsy.net/collect?acquireable=true">Buy Now</a> inventory, Erik (on Engineering)
and Matt (on Marketing) sat down together to see if it could be a good fit for them as well.</p>

<p>Artsy's transactional emails cover everything from internal reporting to messaging for gallery partners, art
collectors and auction bidders. As these emails have evolved and become more complex, our approaches to balancing
beauty with stability have pushed the limits of reasonable human effort. Similar to how frontend frameworks like
<a href="https://getbootstrap.com/">Bootstrap</a> added a level of comfortable abstraction to stylesheets, or the way your
React.js <code>&lt;Button /&gt;</code> component became so much more than a plain old <code>&lt;button /&gt;</code>, MJML's xml 'components' abstract
the messy bits away.</p>

<a name="State.of.the..Email..Union"></a>
<h2>State of the (Email) Union</h2>

<p>Today, we're using MJML for all of our B2C emails, a few of our B2B emails, and our new transactional emails (all
three are generated by different mail services, so it takes some time to bring them all up to date). We've found
that we're able to iterate on designs much faster, and our emails look better in more clients than they ever have
before.</p>

<p>What else have we learned during this process? MJML takes a bit of time to master, especially the idea of
<code>&lt;mj-head&gt;</code> as a kind of global stylesheet and the <code>body --&gt; section --&gt; column</code> flow. Once we got comfortable with
conventions like this, though, life before MJML became hard to imagine. It has offered Artsy the chance to raise
the level of accessibility of design <em>and</em> speed of development in this niche area, a major win for the engineering
team and cross-team collaboration as a whole.</p>

<p>For more information or to get started using MJML, <a href="https://mjml.io">check out their website</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Apogee Technical Retrospective]]></title>
    <link href="http://artsy.github.io/blog/2018/02/06/apogee-technical-retrospective/"/>
    <updated>2018-02-06T00:00:00+00:00</updated>
    <id>http://artsy.github.io/blog/2018/02/06/apogee-technical-retrospective</id>
    <content type="html"><![CDATA[<p>We've previously covered <a href="/blog/2018/02/02/artsy-apogee/">what Apogee is</a> and <a href="/blog/2018/01/24/kubernetes-and-hokusai/">how it's deployed</a>, so all that's left to cover is the technology used to build it. As a refresher: Apogee is a Google Sheets Add-on we built to help our Auctions Ops team transform the data given to us by our partners into a format that our CMS can understand. This process, done manually up until now, takes a long time and is a perfect candidate for automation.</p>

<p>Apogee had some really interesting technical challenges that I enjoyed solving, and I'm excited to share some lessons I learned. So let's dive in!</p>

<!-- more -->


<p>We built a prototype as a "pure" Add-on, written only inside Google's sandbox, but that approach wouldn't work for us in production: the Add-on environment was just too difficult to work with. Google expects you to write Add-ons in their in-browser <a href="http://script.google.com">Script Editor</a> and – while whether or not that editor is <em>good</em> is a matter of preference – the environment isn't suited for collaborating or unit testing. Additionally, we could not get Add-on deploys automated, so we'd like to minimize how often we <em>have</em> to deploy.</p>

<p>So we split things up. Instead of building all Apogee's logic into an Add-on, we decided to build two pieces: a very thin Add-on and a Rails server with all the real logic.</p>

<p>(Because Apogee necessarily includes information about how our partners format their data, we decided not to open source it. Data formats are <em>probably</em> not sensitive, but that's a judgement best left up to our partners.)</p>

<a name="Apogee.Add-on"></a>
<h2>Apogee Add-on</h2>

<p>The Add-on we built is very simple, by design. Our goal was to make an Add-on that was flexible enough such that we would need to deploy it less frequently than adding new parsers.</p>

<p>Add-on responsibilities include:</p>

<ul>
<li>fetching the available parsers from the server.</li>
<li>setting up an Add-on user interface (a menu of partners, each with available parsers).</li>
<li>responding to invocations from that interface.</li>
</ul>


<p>Based on the parser selected by the user, Apogee gathers the required data from the current spreadsheet, sends it to the server for processing, and appends the results to the sheet. Pretty straightforward, you'd think.</p>

<p>Unfortunately, Google Add-ons are a bit... strange. The Add-on itself is executed in Google's datacentres (not the user's browser) and is written in <a href="https://developers.google.com/apps-script/guides/services/#basic_javascript_features">JavaScript 1.6-ish</a>. Specifically, it runs with JavaScript 1.6, plus some features from 1.7, plus some other features from 1.8, and also <a href="https://developers.google.com/apps-script/guides/services/advanced">"Google Advanced Services"</a>. The execution environment also lacks an event loop, which makes sense from Google's perspective (their servers need to know if a script execution has completed) but is still a bit unusual.</p>

<p>Rather than deal with a weird version of JavaScript, we decided to write the Add-on in <a href="https://www.typescriptlang.org">TypeScript</a> and compile down to something Google can execute. We also found <a href="https://www.npmjs.com/package/@types/google-apps-script">open source typings</a> for the Google APIs, which helped a lot. Google also provides access to certain whitelisted libraries, including <a href="https://lodash.com">Lodash</a>, which is handy.</p>

<p>Add-ons also have a somewhat complex permissions and authentication model. The <a href="https://developers.google.com/apps-script/add-ons/lifecycle">documentation</a> provided is a great illustration of why <em>complete</em> documentation is not necessarily <em>effective</em> documentation. If you already understand what you're doing, the docs are a good reference, but I found them difficult to learn from. I really like <a href="https://twitter.com/kosamari/status/852319140060823553">this explanation</a> of how to structure documentation like unit tests.</p>

<p>Permissions vary wildly depending on the execution context. For example, the <code>onOpen</code> callback is able to make network requests when the script is run as an attachment to a spreadsheet, but not when deployed. This makes it difficult to populate our menu UI, which is based off an API response. I learned to not have confidence everything was working until I saw it work end-to-end.</p>

<p>One other peculiarity of Google's API is how UI callbacks work. You could create a menu for your Add-on with the following code:</p>

<pre><code class="js">SpreadsheetApp.getUi()
  .createAddonMenu()
  .addItem('Do something', 'doSomething')
  .addToUi()

function doSomething() {
}
</code></pre>

<p>You'll notice that the callback function is specified by a <em>string</em> representing a function name (and not as a function itself, which would be more idiomatic). So, for every menu item, there must exist a corresponding function in the global scope with a corresponding name. Sadly, no parameters are passed to these callbacks, so it's impossible for a function to determine which menu item it was invoked by. Therefore, every menu item <em>must</em> have exactly <em>one</em> corresponding function. That presents a problem for an Add-on with a dynamic menu.</p>

<p>The Add-on isn't executed in a browser; we're running on Google's datacentres so let's just brute-force this. Our menu is a list of partner names, which is itself a submenu of parsers specific to that partner. That means that each menu item (and corresponding callback) can be indexed by two integers: a partner index and a operation index. So now we have a way to map from our user interface to a specific operation to perform inside <em>one</em> common menu handler.</p>

<p>Let's take a look at the actual code.</p>

<pre><code class="ts">interface Operation {
  name: string
  columns: string[]
  token: string
}

interface Partner {
  name: string
  operations: Operation[]
}

// Sets up the Add-on menu and submenus.
function setupAddon(ui: Partner[]) {
  // Reduce the ui to a list of submenus.
  const addOnMenu = ui.reduce((menu, partner, partnerIndex) =&gt; {
    // Reduce the operations list to a list of menu items.
    return menu.addSubMenu(partner.operations.reduce((memo, operation, operationIndex) =&gt; {
      return memo.addItem(operation.name, `partner${partnerIndex}Operation${operationIndex}`)
    }, SpreadsheetApp.getUi().createMenu(partner.name)))
  }, SpreadsheetApp.getUi().createAddonMenu())
  // Add the generated menu to the Add-on UI.
  addOnMenu.addToUi()
}
</code></pre>

<p>Each menu has a callback function named something like <code>partnerXOperationY</code>. Then we just generated a few thousand functions that match that format and call a shared handler <em>with</em> <code>X</code> and <code>Y</code> as parameters. The generated code looks like this:</p>

<pre><code class="js">function partner0Operation0() {
    sharedHandler(0, 0);
}
function partner0Operation1() {
    sharedHandler(0, 1);
}
function partner0Operation2() {
    sharedHandler(0, 2);
}

function sharedHandler(partnerIndex, operationIndex) {
    // TODO: Look up the appropriate parser to use.
}
</code></pre>

<p>It's not elegant, but it works. Actually, I think it does have a certain elegance, given the constraints it has to operate within.</p>

<p>So that's it! The rest of the challenges were just weird permissions issues or config problems, but the Add-on was pretty easy to build. The file generated by the TypeScript compiler is only 166 lines long, and the file with all our menu callbacks is "only" 8000 lines long. Next, let's talk about the server.</p>

<a name="Apogee.Server"></a>
<h2>Apogee Server</h2>

<p>So, Rails' philosophy is "<a href="https://en.wikipedia.org/wiki/Convention_over_configuration">convention over configuration</a>", which is pretty great as long as you know the conventions. I'd never run <code>rails new</code> before. Also, that philosophy works best when you're building <em>conventional</em> apps. Because Apogee is a bit unconventional, I was going to write Apogee in Sinatra before my colleague suggested I use Rails in <a href="http://guides.rubyonrails.org/api_app.html">API-only mode</a> instead. It seemed a bit overkill, but I also didn't want to pass up the chance to finally learn Rails.</p>

<p>The server has two endpoints:</p>

<ul>
<li><code>/ui</code> provides a list of partners and their respective parsers.</li>
<li><code>/columns</code> accepts spreadsheet columns and returns processed data (cell contents and a background colour to indicate our confidence in parsed results).</li>
</ul>


<p>We needed a way for the server to specify all its operations in a way that they could be invoked through the second endpoint. We decided to use a token-based approach: each parser has a token that can be used to invoke the parser later on. This dovetails with how I structured the parsers, too.</p>

<p>Each partner is defined by a submodule within the <code>Apogee::Parser</code> module, and each parser is defined by a class within that partner module. Let's take a look at some code.</p>

<pre><code class="rb">module Apogee
  module Parser
    module Skinner
      extend Apogee::BaseParser

      class DimensionsParser
        # Name to show in Add-on UI.
        def self.menu_name
          "Parse dimensions from Description column"
        end

        # Columns required by the `/columns` endpoint.
        def self.column_names
          %w[Description]
        end

        # Parse the columns, called from the `/columns` endpoint.
        def self.parse(columns)
          # TODO: parse the columns.
        end
      end
    end
  end
end
</code></pre>

<p>Each class within a partner is expected to have those three class methods.</p>

<p>So now that we have a defined structure for our parsers, we can use Ruby reflection to collect a list of partner modules:</p>

<pre><code class="rb">Parser.constants
  .select { |c| Parser.const_get(c).is_a? Module }
  .map do |c|
    {
      name: c,
      operations: Parser.const_get(c).public_parsers
    }
end
</code></pre>

<p>Each module also has a <code>public_parsers</code> function (inherited from <code>Apogee::BaseParser</code>) which also uses reflection:</p>

<pre><code class="rb">def public_parsers
  constants
    .select { |c| const_get(c).is_a? Class }
    .map { |c| const_get(c) }
    .map do |klass|
      {
        klass: klass.to_s,
        name: klass.menu_name,
        columns: klass.column_names,
        token: Digest::SHA256.base64digest(klass.to_s)
      }
    end
end
</code></pre>

<p>This code collects all the Ruby classes inside a module into a data structure that can be consumed by the Apogee Add-on through the <code>/ui</code> endpoint. As a bonus, the tokens are generated from the SHA256 hash of the fully-qualified parser class names. And we also avoid having to maintain a separate list of parsers that I would inevitably forget to update. Win-win.</p>

<p>All that's left to do is to lookup a parser class from a token. This is as easy as finding the class with the matching token and calling its <code>parse</code> function.</p>

<pre><code class="rb">parser = partners
  .map { |p| p[:operations] }
  .flatten
  .find { |op| op[:token] == token }
Object.const_get(parser[:klass]).parse(columns)
</code></pre>

<p>Neat!</p>

<p>This approach is <em>good</em>, but strikes me as overly object-oriented. <em>Most</em> of the parsers we're going to write are going to do the same thing: they have the same three methods and the <code>parse</code> method is basically just matching each spreadsheet cell against a regular expression. We can make a better abstraction.</p>

<p>Since the parsers are defined by the presence of a class within a partner module, we can use metaprogramming to abstract away all the common pieces and add classes to the module programmatically. The implementation is too in-depth to explain in detail here, but our partner module above could be rewritten to look like the following:</p>

<pre><code class="rb">module Apogee
  module Parser
    module Skinner
      extend Apogee::BaseParser

      add_single_column_parser(
        class_name: 'DimensionsParser',
        menu_name: 'Parse dimensions from Description column',
        column_name: 'Description',
        regex: %r{REGEX GOES HERE},
        new_columns: %w[Height Width Depth Unit]
      ) do |match|
        # TODO: Process each cell.
      end
    end
  end
end
</code></pre>

<p>I created two such methods: one that uses a single regex, and another that uses multiple regexes (for more complex needs). I also wrote a handy <code>add_all_parser</code> method which adds a sort of meta-parser, which collates the results from calling <code>parse</code> on all the <em>other</em> parsers in that module. Our Ops team just needs to click "Parse everything" and the entire spreadsheet is processed with all the parsers in seconds.</p>

<p>And of course, since all our parsers are just Ruby classes, they were easy to unit test.</p>

<p>I've done metaprogramming in other languages, and it was a lot of fun to use it in Ruby. I ran the code by my colleagues who are more experienced in Ruby than I am, and documented everything thoroughly. It's a real shame the codebase isn't open source, because I'm really proud of the approach and would love to share it with you.</p>

<a name="Apogee.Authentication"></a>
<h2>Apogee Authentication</h2>

<p>We needed to make sure that only the Add-on itself was invoking the server's endpoints. Not because the server has sensitive data – Apogee's server has no database and doesn't access any APIs – but just because it's good practice to limit access to services to only who needs them.</p>

<p>We evaluated a bunch of prospective auth strategies, including (but not limited to) the following:</p>

<ul>
<li>Whitelist Google datacentre IP addresses, block all others.</li>
<li>HTTP Basic Auth.</li>
<li>Shared secret.</li>
<li>OAuth with Artsy's API, by the user upon Add-on installation.</li>
<li>Something totally custom, or a combination of any of these.</li>
</ul>


<p>After thoughtful discussion, we decided on a solution that works for us. I'm not going to specify what we used – not because I'm that concerned about the security, but because each project and team will have their own needs. If you build a server, think carefully about what kind of authentication makes sense for you and your team.</p>

<a name="Conclusion"></a>
<h2>Conclusion</h2>

<p>Apogee was a really fun project. It had a defined scope, so it was a good first Rails project for me to tackle. The Add-on helps my colleagues on the Auctions Ops team do their jobs easier, so it was intrinsically rewarding to build. And it turns out that our Gallery Partnerships team also has to import a lot of partner data into Artsy's CMS, so I'm now exploring ways Apogee can help them, too.</p>

<p>As a closing note, I want to discuss something that's been on my mind lately. I've been developing iOS apps <a href="https://ashfurrow.com/blog/5-years-of-ios/">since 2009</a>, and have a <a href="https://ashfurrow.com/books/">very intimate knowledge</a> of Objective-C, Swift, and UIKit. For a long time, I actually avoided learning new languages and frameworks because they intimidated me – starting over in a new framework, from scratch, felt like a step backward.</p>

<p>I think this is a common frame of mind, among iOS developers, among all developers. But now I regret avoiding new technology for so long. The languages and tools that I knew had become part of my identity: I was an "iOS Developer." That identity was a source of strength, but was also a limitation.</p>

<p>Developers solve problems. Sometimes those problems are best solved with iOS apps. And sometimes, they're best solved with spreadsheet plugins. After <a href="https://ashfurrow.com/blog/swift-vs-react-native-feels/">realizing</a> last year that I was limiting myself, I'm still coming to terms with how that impacts my identity. But I'll say this: if <em>I</em> can leave the safety blanket of the iOS world and build something completely new, so can you. Don't let your expertise and experience limit what you think you can build.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Apogee: Doing More with Less]]></title>
    <link href="http://artsy.github.io/blog/2018/02/02/artsy-apogee/"/>
    <updated>2018-02-02T00:00:00+00:00</updated>
    <id>http://artsy.github.io/blog/2018/02/02/artsy-apogee</id>
    <content type="html"><![CDATA[<blockquote><p>Apogee: the point in the orbit of two objects at which they are furthest apart.</p></blockquote>

<p>In 2017, the Artsy Auctions Operations team coordinated and ran 190+ sales on our platform. This year, our ambitions are set even higher. But scaling up the number of sales we run will require scaling up our tools and processes, too. This post describes Apogee, a tool I built to help us scale our businesses processes. I never thought I would be so excited to build a spreadsheet plugin, but I honestly had a blast. So let's dive in!</p>

<!-- more -->


<p>Running a sale on Artsy is no small feat. I mean, after all the contract negotiations you might think things get easier, but that's just the beginning of the work. All our auction partners have data in their own CMS systems, and they're all formatted slightly differently. We need to get the information for each lot in a sale into Artsy's CMS, and so a few years ago we built a batch-import app in Rails to do this (closed source, sorry). It works well, but expects data in a specific format.</p>

<p>A lot of work is done by our Ops team to reformat spreadsheets they get from our partners to match the structure our batch import tool expects. All of our partners have different formats, and sales can include hundreds of lots. The reformatting process can take one person over a day, for large sales.</p>

<p>Wouldn't it be cool to build some kind of server to bridge the gulf between Artsy's database and our partner's myriad systems?</p>

<p>No, actually, it wouldn't. It would be a tremendous amount of work, from our side and from theirs. Back to the drawing board.</p>

<p>In January, Ops arranged a meeting between us engineers and an auction partner. Ideally, a solution to <em>our</em> problem would also make our partners' lives easier, since exporting data from their systems is sometimes as arduous as importing it into ours. <a href="https://www.skinnerinc.com">Skinner</a> was kind enough to walk us through their export process and provide us with some representative data.</p>

<p>Perfect, now we have a starting point.</p>

<hr />

<blockquote><p>If you're not familiar the 80/20 rule says, ‘Do a job until it's 80% done and then quit’.
—<a href="https://www.youtube.com/watch?v=MSgR-hJjdTo#t=2m36s">@searls</a></p></blockquote>

<p>The team's early brainstorming to the Ops import workflow was hampered by a kind of perfectionism. We evaluated, but decided against solutions because they didn't address all the edge cases. It finally clicked, for me anyway, when I realized that our tool didn't need to bridge the gulf between two <em>systems</em>, but between two <em>workflows</em>.</p>

<p>And it didn't need to be perfect, not at all. Even an 80% reduction in the amount of time spent wrangling spreadsheet data would translate to <em>hours</em> of time saved, per sale. That is, if we could find a way to make it ridiculously easy to add parsers for new partners.</p>

<p>We built a quick prototype – less than two days work – to pull out data from Skinner's spreadsheets and format it into the structure that's easiest to import into Artsy. The prototype itself was a <a href="https://developers.google.com/apps-script/add-ons/">Google Sheets Add-on</a>. There will be a follow-up post describing the technical evolution of this tool, but the important thing to note here is that we engineers had to go to where our Ops team already was. Previous discussions around improving Ops' import workflows were centred around building entirely new workflows instead of improving the existing, functional workflows.</p>

<p>The prototype was tested in production with two large sales Skinner and Artsy were running together. Parsing out <em>just</em> the dimensions of the lots, for <em>just</em> one of the sales, saved an hour of Ops' time. Clearly, there was promise in this tool.</p>

<p>Next steps were all technical, and we'll get into details in the next post, but building Apogee actually involved developing two pieces of technology: a Rails server, and an Add-on client. Because a tool to parse data from various partners necessarily contains those partners' data formats, we decided not to open source Apogee. That's okay – we practice <a href="https://ashfurrow.com/blog/open-source-ideology/">open source <em>by default</em></a>, not <em>by demand</em>.</p>

<a name="Apogee.Server"></a>
<h2>Apogee Server</h2>

<p>It's difficult to discuss the server without first talking about the Add-on, so in short: Add-ons are difficult to maintain, to collaborate on, to unit test, and so on. So we decided early to build a very thin Add-on client and move all the heavy lifting to a backend server that we could develop within our existing technical framework. Our goal was to build an Add-on that needed to be updated less frequently than support for new partners was added.</p>

<p>We needed a server. Most of this server's job was going to be running regular expressions, and Ruby's regex features are still a step above Node's. It's critical that writing new parsers be <em>ridiculously</em> easy to write (and test!). That factored in a lot of technical decisions, which we'll discuss in more detail in the next Apogee post.</p>

<p>So it's a Ruby server, but which framework?</p>

<p>I thought about using Sinatra, since our server is very simple and Sinatra is a tech I've <a href="https://github.com/Moya/Aeryn">used before</a>, but after speaking with some colleagues, I decided on using Rails in API-only mode. Sticking to Rails would keep the project in-step with the rest of Artsy's Ruby server code – we don't have any Sinatra apps, but everyone here already knows Rails. Plus, Rails is <em>very</em> boring and – consequently – <em>very</em> stable. I like stability.</p>

<p>Before a few weeks ago, I'd never even run <code>rails new</code>. Now, I'm the proud point-person for an entire Rails server. I owe a lot to my colleagues for helping me along the way.</p>

<a name="Apogee.Add-on"></a>
<h2>Apogee Add-on</h2>

<p>The Add-on is an interesting piece of code. In addition to the strange environment for building and deploying Add-ons, you also have to deal with a strange runtime. How strange? Well, it's JavaScript, but not as we know it.</p>

<p>Google Docs Add-ons run as <a href="https://script.google.com">Google Scripts</a>, which are a more general-purpose cloud computing platform. They <a href="https://developers.google.com/apps-script/guides/services/#basic_javascript_features">execute a runtime</a> based on JavaScript 1.6, which specific features from JavaScripts 1.7 and 1.8 ported in. Similar to the <a href="http://danger.systems/js/">Danger-JS</a> 1.x runtime, there is no event loop. So, things are weird.</p>

<p>Just because we can't fully automate deploys doesn't mean we can't automate <em>parts</em> of the process. Specifically, I built the Add-on using <a href="https://www.typescriptlang.org">TypeScript</a> which is compiled down to a version of JavaScript that Google Scripts plays nice with. There are even open-source <a href="https://www.npmjs.com/package/@types/google-apps-script">typings</a> available for the Google Scripts API.</p>

<hr />

<p>I learned a lot from building Apogee, from a technical perspective, but the lessons I'm most proud of learning have to do more with business processes. From the general approach of making data imports faster, to the specific programming languages used to build Apogee, all decisions were driven first and foremost by actual business needs (and not technology trends). Apogee is not exciting enough to make the front page of Hacker News, and in a weird way, I'm proud of that.</p>

<p>Artsy Auctions are at an inflection point; we need to scale up the number of auctions we run faster than we scale up the effort spends actually running them. 2018 is going to challenge the Auctions engineering team to help our colleagues accomplish more, while doing less. I'm excited for that challenge.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Presenters and Memoization: Moving Logic out of Templates]]></title>
    <link href="http://artsy.github.io/blog/2014/03/18/presenters-and-memoization-moving-logic-out-of-templates/"/>
    <updated>2014-03-18T17:27:00+00:00</updated>
    <id>http://artsy.github.io/blog/2014/03/18/presenters-and-memoization-moving-logic-out-of-templates</id>
    <content type="html"><![CDATA[<p>When dealing with rendering data for an email, one frequently has to make many database calls to assemble the required data. This can be slow, and depending on how you structure the code that is assembling the data vs rendering the data in a template, it's very easy to be making repeated calls, which can significantly slow down your process. Additionally, whether you are using <a href="http://haml.info/">Haml</a>, <a href="http://mustache.github.io/">Mustache</a>, <a href="http://jade-lang.com/">Jade</a>, or any other templating language, embedding too much logic in the template can making things hard to maintain (especially if some logic lives in the template and some elsewhere in your domain code). Of course some logic in the template (a conditional: should I render this section?, or loops: render this hash of data) is necessary, but I like to keep as much out of there as possible. It's easier to optimize, debug and maintain that logic elsewhere, and also writing complex logic in <a href="https://www.ruby-lang.org">Ruby</a> is much more fun than in a templating language!</p>

<p>In this article I'll present what I've been doing to keep my templates relatively logic-free, and how I make sure I don't repeat any heavy database calls in assembling my data.</p>

<!-- more -->


<a name="The.Setup.-.Presenters.and.Memoization"></a>
<h2>The Setup - Presenters and Memoization</h2>

<p>First, I'd like to introduce the Presenter pattern, and how this can help clean up your templates. Here are a couple of links about using presenters with <a href="http://rubyonrails.org/">Rails</a> that I've found useful:</p>

<ul>
<li><a href="http://blog.jayfields.com/2007/03/rails-presenter-pattern.html">Jay Fields' Guide to Presenters</a></li>
<li><a href="http://www.slideshare.net/mdesjardins/presenters-in-rails">Mike Desjardins' Slideshare Presentation</a></li>
</ul>


<p>Consider the following screenshot of a section of a weekly email that we send our users:</p>

<p><img src="/images/2014-03-18-presenters-and-memoization-moving-logic-out-of-templates/recently_added.png" alt="Example of Recently Added Works" /></p>

<p>This section shows works that have been added that week by artists that you follow. That's clearly going to involve some database calls, and potentially heavy ones at that. Now we'd like to accomplish two things here: we want to make sure that we only make these calls once (no matter what we wind up doing with the data later), and we also would like to make sure that any code or logic that is making these calls and doing any data manipulation is not being done directly in our templates. Keeping this kind of logic out of your template will make it easier to debug, maintain and write.</p>

<p>Let's start by creating a Module to hold the various logic required for this email:</p>

<pre><code class="ruby">class WeeklyEmailPresenter
  def initialize(user)
    @user = user
  end
end
</code></pre>

<p>Ok, so far so good. In our mail template rendering/calling code, we can now say:</p>

<pre><code class="ruby">@presenter = WeeklyEmailPresenter.new(user)
</code></pre>

<p>This will allow us to refer to methods in this class in our mail template. So now let's add a method that will query our database and return a list of artists that this user should be notified about:</p>

<pre><code class="ruby">class WeeklyEmailPresenter
  def initialize(user)
    @user = user
  end

  def recently_added_works
    # Some really heavy database query
  end
end
</code></pre>

<p>Ok, that was easy. In our HAML template, we can now do:</p>

<pre><code class="haml">-if @presenter.recently_added_works &amp;&amp; @presenter.recently_added_works.any?
  %table
    %tr
      %td
        -@presenter.recently_added_works.each do |artists|
          &lt;!-- markup to render each artist with recently added works --&gt;
</code></pre>

<p>However, take a look at how many times we've referred to <code>@presenter.recently_added_works</code> - 3 times already! And we'll most likely refer to it more elsewhere (perhaps when deriving a subject line, or showing a total count somewhere, etc.). Depending on how you've implemented the method <code>recently_added_works</code>, you may be re-querying the database every time it's referred to! Clearly that's a lot of wasted resources. So, let's look at an easy change that will guarantee we only ever perform the work to assemble this data once. We memoize it:</p>

<pre><code class="ruby">class WeeklyEmailPresenter
  def initialize(user)
    @user = user
  end

  def recently_added_works
    @recently_added_works ||= build_recently_added_works
  end

  private

  def build_recently_added_works
    # Code to do database lookups
  end
end
</code></pre>

<p>All we're doing is moving the actual code that's doing the heavy lifting into a <code>private</code> method (for convention, I like to prefix the name with <code>build_</code>). The public method that we refer to elsewhere in our presenter and template simply calls the appropriate <code>private</code> method. Through using an instance variable combined with conditional assignment, we guarantee that the <code>build_</code> method (our heavy and slow workhorse method) will only be called once, no matter how many times we refer to the public method.</p>

<p>That's it! To summarize, use instance variables in your public methods which is what your templates and other code will use. Those public methods should call private <code>build_</code> methods which actually do all the heavy lifting. This way, you get to easily move logic away from a template and into its own module, and can guarantee that you're not repeating any long-running database queries or other slow data processing.</p>

<p>Hopefully you've found this a useful pattern to follow, please leave any feedback in the comments and <a href="https://github.com/artsy">follow us on Github</a>!</p>
]]></content>
  </entry>
  
</feed>
